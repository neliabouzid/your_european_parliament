{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4a94e2",
   "metadata": {},
   "source": [
    "# Scraping the Legislative Observatory : scraping all information available on each procedure except the leglisative texts themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef601c",
   "metadata": {},
   "source": [
    "## 1. Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c76f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f4e6c",
   "metadata": {},
   "source": [
    "## 2. Chrome driver initialization and creation of a list of urls to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2644cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe containing only one row with \n",
    "df = pd.read_csv('list_urls_2025.csv') # Update : December 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79e2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Turning the dataframe's unique row into a list\n",
    "urls_total = ast.literal_eval(df['urls'][0])\n",
    "# Only keeping the ordinary legislative procedures \n",
    "urls_cod = [url for url in urls_total if re.search(r'COD', url)]\n",
    "# Splitting the list into multiple lists of 100 urls\n",
    "list_size = 50\n",
    "lists = [urls_cod[i:i+list_size] for i in range(0, len(urls_cod), list_size)]\n",
    "print(len(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f024c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abd7ab",
   "metadata": {},
   "source": [
    "## 3. Scraping the Legislative Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65cd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the reference from the URL\n",
    "def extract_reference(url):\n",
    "    # Use regex to extract the reference pattern from the URL\n",
    "    match = re.search(r'en/procedure-file\\?reference=(\\d+)/(\\d+)\\(([A-Za-z]+)\\)', url)\n",
    "    if match:\n",
    "        # Reconstruct the reference string in the same format\n",
    "        return f\"{match.group(1)}/{match.group(2)}({match.group(3)})\"\n",
    "    else:\n",
    "        # Return None if the pattern isn't found\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Function to extract texts and links from a cell into a list or string\n",
    "def extract_cell_content(cell):\n",
    "    \"\"\"Extracts text and links from a cell into a list or string.\"\"\"\n",
    "    links = cell.find_all(\"a\")\n",
    "    if links:\n",
    "        # Initialize a list to store both text and link data\n",
    "        values = []\n",
    "        for content in cell.contents:\n",
    "            # If the content is an <a> tag, store its text and href\n",
    "            if getattr(content, \"name\", None) == \"a\":\n",
    "                values.append({\n",
    "                    \"text\": content.get_text(strip=True),\n",
    "                    \"href\": content.get(\"href\")\n",
    "                })\n",
    "            # If it's plain text, store it separately\n",
    "            elif isinstance(content, str):\n",
    "                text = content.strip()\n",
    "                if text:\n",
    "                    values.append({\"text\": text})\n",
    "        # Return a list of dictionaries for each element found in the cell\n",
    "        return values\n",
    "    else:\n",
    "        # If no links, just return the text content of the cell\n",
    "        return cell.get_text(\" \", strip=True)\n",
    "    \n",
    "def clean_text(text):\n",
    "    \"\"\"Helper to remove brackets and extra whitespace.\"\"\"\n",
    "    if not text: return \"\"\n",
    "    # Removes [ and ] and strips whitespace\n",
    "    return re.sub(r'[\\[\\]]', '', str(text)).strip()\n",
    "\n",
    "\n",
    "def parse_table_doc_gateway(table, institution_name):\n",
    "    \"\"\"\n",
    "    Parses table for the \"documentation gateway\" and injects Institution immediately.\n",
    "    Cleans content during extraction.\n",
    "    \"\"\"\n",
    "    headers = [th.get_text(strip=True) for th in table.select(\"thead th\")]\n",
    "    rows = []\n",
    "\n",
    "    # Case 1: Row-based table\n",
    "    if headers:\n",
    "        for tr in table.select(\"tbody tr\"):\n",
    "            cells = tr.find_all([\"td\", \"th\"])\n",
    "            if len(cells) >= len(headers):\n",
    "                # Build dict and clean content on the fly\n",
    "                row_data = {\"Institution\": institution_name}\n",
    "                for i, header in enumerate(headers):\n",
    "                    # Direct cleaning here\n",
    "                    content = extract_cell_content(cells[i])\n",
    "                    row_data[header] = clean_text(content)\n",
    "                rows.append(row_data)\n",
    "        return rows\n",
    "\n",
    "    # Case 2: Key-value style\n",
    "    else:\n",
    "        kv_dict = {\"Institution\": institution_name}\n",
    "        for tr in table.select(\"tr\"):\n",
    "            th = tr.find(\"th\")\n",
    "            td = tr.find(\"td\")\n",
    "            if th and td:\n",
    "                key = th.get_text(strip=True)\n",
    "                kv_dict[key] = clean_text(extract_cell_content(td))\n",
    "        return [kv_dict] if kv_dict != {\"Institution\": institution_name} else []\n",
    "\n",
    "\n",
    "# Function to parse a table into a list of dicts or a dict\n",
    "def parse_table(table):\n",
    "    \"\"\"\n",
    "    Parses an HTML table into:\n",
    "      - a list of dicts if it has <thead> (row-based table),\n",
    "      - a single dict if it's key–value style (<th><td> rows).\n",
    "    \"\"\"\n",
    "    # Extract all header names from the table\n",
    "    headers = [th.get_text(strip=True) for th in table.select(\"thead th\")]\n",
    "\n",
    "    # Case 1: standard row-based table with headers\n",
    "    if headers:\n",
    "        rows = []\n",
    "        # Loop through each row in the <tbody>\n",
    "        for tr in table.select(\"tbody tr\"):\n",
    "            cells = tr.find_all([\"td\", \"th\"])\n",
    "            # Match cells to headers if lengths are equal\n",
    "            if len(cells) == len(headers):\n",
    "                row = {\n",
    "                    headers[i]: extract_cell_content(cells[i])\n",
    "                    for i in range(len(headers))\n",
    "                }\n",
    "            # If only one cell (possibly a note row)\n",
    "            elif len(cells) == 1:\n",
    "                row = {\"Note\": extract_cell_content(cells[0])}\n",
    "            # Otherwise, handle mismatched columns\n",
    "            else:\n",
    "                row = {\n",
    "                    headers[i] if i < len(headers) else f\"Column {i+1}\": extract_cell_content(cells[i])\n",
    "                    for i in range(len(cells))\n",
    "                }\n",
    "            # Append processed row dictionary to list\n",
    "            rows.append(row)\n",
    "        return rows\n",
    "\n",
    "    # Case 2: key–value style table (no headers)\n",
    "    else:\n",
    "        kv_dict = {}\n",
    "        # Iterate through each table row\n",
    "        for tr in table.select(\"tr\"):\n",
    "            th = tr.find(\"th\")\n",
    "            td = tr.find(\"td\")\n",
    "            # If both a header cell and a data cell exist, store them as key-value pairs\n",
    "            if th and td:\n",
    "                kv_dict[th.get_text(strip=True)] = extract_cell_content(td)\n",
    "        # Return a dictionary of key–value pairs\n",
    "        return kv_dict\n",
    "\n",
    "\n",
    "def scrape_key_players(soup):\n",
    "    \"\"\"Specialized extraction for the Key Players section including shadows.\"\"\"\n",
    "    result = {}\n",
    "    key_players_section = soup.select_one('#erplAccordionKeyPlayers')\n",
    "    if not key_players_section:\n",
    "        return 'N/A'\n",
    "\n",
    "    for li in key_players_section.select('ul > li.es_accordion-item'):\n",
    "        inst_name = li.find('button').get_text(strip=True)\n",
    "        institution_entries = []\n",
    "        tables = li.select('table')\n",
    "\n",
    "        if not tables:\n",
    "            result[inst_name] = []\n",
    "            continue\n",
    "\n",
    "        for table in tables:\n",
    "            headers = [th.get_text(\" \", strip=True) for th in table.select('thead th')]\n",
    "            last_entry = None\n",
    "\n",
    "            for row in table.select('tbody tr'):\n",
    "                # 1. Handle Pending rows\n",
    "                if \"Pending final decision\" in row.get_text():\n",
    "                    entry = {h: \"Pending final decision\" for h in headers}\n",
    "                    institution_entries.append(entry)\n",
    "                    continue\n",
    "\n",
    "                # 2. Handle Shadow Rapporteurs (Merged into last entry)\n",
    "                if row.select_one('#collapseShadowRapporteur'):\n",
    "                    shadows = [a.get_text(\" \", strip=True) for a in row.select('a.rapporteur')]\n",
    "                    if last_entry and shadows:\n",
    "                        last_entry[\"Shadow rapporteurs\"] = shadows\n",
    "                    continue\n",
    "\n",
    "                # 3. Handle Normal Rows\n",
    "                cells = row.find_all(['th', 'td'])\n",
    "                if not cells: continue\n",
    "                \n",
    "                entry = {headers[i]: \" \".join(cells[i].stripped_strings) \n",
    "                         for i in range(min(len(headers), len(cells)))}\n",
    "                \n",
    "                institution_entries.append(entry)\n",
    "                last_entry = entry\n",
    "\n",
    "        result[inst_name] = institution_entries\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb303511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracking variables, to keep track of the urls that were not scraped correctly\n",
    "url_not_found = []\n",
    "url_no_title = []\n",
    "url_missing_title_span = {}  # dict with the following form: {url: [sections_with_missing_title_span]}\n",
    "\n",
    "# Initialize main DataFrame\n",
    "df = pd.DataFrame(columns=[\n",
    "    'url', \n",
    "    'reference', \n",
    "    'title', \n",
    "    'subjects', \n",
    "    'key_players',\n",
    "    'key_events', \n",
    "    'technical_info', \n",
    "    'documentation_gateway',\n",
    "    'transparency', \n",
    "    'final_act'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872d672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing list 1 of 3\n",
      "Batch 1 saved with 50 URLs\n",
      "Processing list 2 of 3\n",
      "Batch 2 saved with 50 URLs\n",
      "Processing list 3 of 3\n",
      "Batch 3 saved with 19 URLs\n",
      "Scraping complete.\n"
     ]
    }
   ],
   "source": [
    "# Loop over each list of URLs\n",
    "j = 1\n",
    "for urls in lists:\n",
    "    print(f'Processing list {j} of {len(lists)}')\n",
    "    \n",
    "    # Temporary storage for rows collected from this batch\n",
    "    batch_rows = []\n",
    "\n",
    "    # Loop through each URL in the current list\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Extract reference from the URL\n",
    "            reference_ = extract_reference(url)\n",
    "\n",
    "            # If no reference found, log and skip to next\n",
    "            if not reference_:\n",
    "                url_not_found.append(url)\n",
    "                batch_rows.append({\n",
    "                    'url': url,\n",
    "                    'reference': 'N/A',\n",
    "                    'title': 'N/A',\n",
    "                    'subjects': 'N/A',\n",
    "                    'key_players': 'N/A',\n",
    "                    'key_events': 'N/A',\n",
    "                    'technical_info': 'N/A',\n",
    "                    'documentation_gateway': 'N/A',\n",
    "                    'transparency': 'N/A',\n",
    "                    'final_act': 'N/A'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Open the webpage using Selenium\n",
    "            driver.get(url)\n",
    "            time.sleep(1)  # Allow time for page to load fully\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Scrape the title of the procedure\n",
    "            title_element = soup.find('h2', class_=\"es_title-h2 mb-3\")\n",
    "            title = title_element.text.strip() if title_element else 'N/A'\n",
    "            if title == 'N/A':\n",
    "                url_no_title.append(url)\n",
    "\n",
    "            # Scrape the subjects of the procedure\n",
    "            subjects = 'N/A'\n",
    "            subj_label = soup.find(\"p\", class_=\"font-weight-bold mb-1\", string=\"Subject\")\n",
    "\n",
    "            if subj_label:\n",
    "                subj_value = subj_label.find_next_sibling()\n",
    "                if subj_value:\n",
    "                    # Adding \", \" as the first argument to get_text() automatically \n",
    "                    # inserts a comma between each text element found \n",
    "                    # (the codes and labels).\n",
    "                    subjects = subj_value.get_text(\", \", strip=True)\n",
    "\n",
    "            # Scrape the key players section (institutions involved)\n",
    "            key_players = scrape_key_players(soup)\n",
    "\n",
    "            # Scrape key events (chronological information)\n",
    "            key_events = 'N/A'\n",
    "            key_events_section = soup.find(\"h2\", string=lambda x: x and \"Key events\" in x)\n",
    "            if key_events_section:\n",
    "                key_events = {}\n",
    "                table = key_events_section.find_next(\"table\")\n",
    "                if table:\n",
    "                    rows = parse_table(table)\n",
    "                    # Use date as key if available\n",
    "                    for row in rows:\n",
    "                        date_key = row.get(\"Date\", f\"event_{len(key_events)+1}\")\n",
    "                        key_events.setdefault(date_key, []).append(row)\n",
    "\n",
    "            # Scrape technical information section\n",
    "            tech_info = 'N/A'\n",
    "            tech_info_section = soup.find(\"h2\", string=lambda x: x and \"Technical information\" in x)\n",
    "            if tech_info_section:\n",
    "                table = tech_info_section.find_next(\"table\")\n",
    "                if table:\n",
    "                    tech_info = parse_table(table)\n",
    "\n",
    "            section_doc = soup.find(\"div\", id=\"section6\")\n",
    "            doc_list = []\n",
    "\n",
    "            if section_doc:\n",
    "                for li in section_doc.find_all(\"li\", class_=\"es_accordion-item\"):\n",
    "                    title_span = li.select_one(\"button span.t-x\")\n",
    "                    if not title_span:\n",
    "                        continue\n",
    "                        \n",
    "                    inst_name = title_span.get_text(strip=True)\n",
    "                    \n",
    "                    for table in li.select(\"table\"):\n",
    "                        # This now returns a list of clean dicts including the institution\n",
    "                        table_data = parse_table_doc_gateway(table, inst_name)\n",
    "                        doc_list.extend(table_data)\n",
    "\n",
    "                # Sort the list by date immediately before saving to the DF\n",
    "                doc_list.sort(\n",
    "                    key=lambda d: datetime.strptime(d.get(\"Date\", \"01/01/1900\"), \"%d/%m/%Y\") \n",
    "                    if d.get(\"Date\") else datetime(1900, 1, 1)\n",
    "                )\n",
    "\n",
    "            documentation = doc_list if doc_list else 'N/A'\n",
    "            \n",
    "            # Scrape transparency section (if available)\n",
    "            transp = 'N/A'\n",
    "            section_transp = soup.find(\"div\", id=\"section8\")\n",
    "            if section_transp:\n",
    "                transp = {}\n",
    "                for li in section_transp.find_all(\"li\", class_=\"es_accordion-item\"):\n",
    "                    title_span = li.select_one(\"button span.t-x\")\n",
    "                    if not title_span:\n",
    "                        url_missing_title_span.setdefault(url, []).append(\"Transparency\")\n",
    "                        continue\n",
    "                    name = title_span.get_text(strip=True)\n",
    "                    transp[name] = []\n",
    "                    for table in li.select(\"table\"):\n",
    "                        transp[name].extend(parse_table(table))\n",
    "\n",
    "            # Scrape final act section (links to final documents)\n",
    "            final_act = 'N/A'\n",
    "            section_final_act = soup.find(\"div\", id=\"section9\")\n",
    "            if section_final_act:\n",
    "                final_act = {}\n",
    "                for li in section_final_act.select(\"div.es_links-list ul li\"):\n",
    "                    for link in li.find_all(\"a\", href=True):\n",
    "                        key = link.get_text(strip=True)\n",
    "                        final_act[key] = link[\"href\"]\n",
    "\n",
    "            # Store all scraped data into one dictionary for this URL\n",
    "            batch_rows.append({\n",
    "                'url': url,\n",
    "                'reference': reference_,\n",
    "                'title': title,\n",
    "                'subjects': subjects,\n",
    "                'key_players': key_players,\n",
    "                'key_events': key_events,\n",
    "                'technical_info': tech_info,\n",
    "                'documentation_gateway': documentation,\n",
    "                'transparency': transp,\n",
    "                'final_act': final_act\n",
    "            })\n",
    "\n",
    "        # Error handling for any issues during scraping\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {url}: {e}\")\n",
    "            url_not_found.append(url)\n",
    "            # Append placeholder data for failed URLs\n",
    "            batch_rows.append({\n",
    "                'url': url,\n",
    "                'reference': 'N/A',\n",
    "                'title': 'N/A',\n",
    "                'subjects': 'N/A',\n",
    "                'key_players': 'N/A',\n",
    "                'key_events': 'N/A',\n",
    "                'technical_info': 'N/A',\n",
    "                'documentation_gateway': 'N/A',\n",
    "                'transparency': 'N/A',\n",
    "                'final_act': 'N/A'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "    # After processing one list of URLs, save intermediate progress\n",
    "    if batch_rows:\n",
    "        batch_df = pd.DataFrame(batch_rows)\n",
    "        # Append current batch to the main dataframe\n",
    "        df = pd.concat([df, batch_df], ignore_index=True)\n",
    "\n",
    "        # Save batch progress to a CSV file\n",
    "        df.to_csv(f\"scrape_progress_batch_2025_{j}.csv\", index=False)\n",
    "        print(f\"Batch {j} saved with {len(batch_rows)} URLs\")\n",
    "\n",
    "    j += 1  # Move to the next batch index\n",
    "\n",
    "# Close Selenium driver after all scraping is done\n",
    "driver.quit()\n",
    "print('Scraping complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f808845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "df.to_csv(\"final_scrape_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec9d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tracking structures to DataFrames\n",
    "df_not_found = pd.DataFrame({'url': url_not_found})\n",
    "df_no_title = pd.DataFrame({'url': url_no_title})\n",
    "\n",
    "# For missing title spans, expand the dict into a DataFrame\n",
    "df_missing_title_span = pd.DataFrame(\n",
    "    [(url, section) for url, sections in url_missing_title_span.items() for section in sections],\n",
    "    columns=['url', 'missing_section']\n",
    ")\n",
    "\n",
    "# Save them all\n",
    "df_not_found.to_csv(\"urls_not_found_2025.csv\", index=False)\n",
    "df_no_title.to_csv(\"urls_no_title_2025.csv\", index=False)\n",
    "df_missing_title_span.to_csv(\"urls_missing_title_span_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e39ae9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>reference</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>key_players</th>\n",
       "      <th>key_events</th>\n",
       "      <th>technical_info</th>\n",
       "      <th>documentation_gateway</th>\n",
       "      <th>transparency</th>\n",
       "      <th>final_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0255(COD)</td>\n",
       "      <td>Justice programme 2028-2034</td>\n",
       "      <td>7.40.02 Judicial cooperation in civil and comm...</td>\n",
       "      <td>{'European Parliament': [{'Joint committee res...</td>\n",
       "      <td>{'03/09/2025': [{'Date': '03/09/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0255(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0405(COD)</td>\n",
       "      <td>Placing on the market of genetically modified ...</td>\n",
       "      <td>3.10.09.06 Agro-genetics, GMOs, 4.60.02 Consum...</td>\n",
       "      <td>{'European Parliament': [{'Joint committee res...</td>\n",
       "      <td>{'16/12/2025': [{'Date': '16/12/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0405(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0540(COD)</td>\n",
       "      <td>Union support for asylum, migration and integr...</td>\n",
       "      <td>7.10 Free movement and integration of third-co...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'16/07/2025': [{'Date': '16/07/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0540(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>{'Other Members': [{'Name': [{'text': 'ASENS L...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0550(COD)</td>\n",
       "      <td>'AgoraEU' programme 2028–2034</td>\n",
       "      <td>1.20 Citizen's rights, 4.10.03 Child protectio...</td>\n",
       "      <td>{'European Parliament': [{'Joint committee res...</td>\n",
       "      <td>{'16/07/2025': [{'Date': '16/07/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0550(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>{'Rapporteurs, Shadow Rapporteurs and Committe...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0227(COD)</td>\n",
       "      <td>Global Europe</td>\n",
       "      <td>6.20 Common commercial policy in general, 8.70...</td>\n",
       "      <td>{'European Parliament': [{'Joint committee res...</td>\n",
       "      <td>{'16/07/2025': [{'Date': '16/07/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0227(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0232(COD)</td>\n",
       "      <td>Protection of workers from the risks related t...</td>\n",
       "      <td>4.15.15 Health and safety at work, occupationa...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'18/07/2025': [{'Date': '18/07/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0232(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>{'Rapporteurs, Shadow Rapporteurs and Committe...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0074(COD)</td>\n",
       "      <td>Extension of the timeframe for the establishme...</td>\n",
       "      <td>7.30.30 Action to combat crime, 7.40.04 Judici...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'02/04/2025': [{'Date': '02/04/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0074(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>{'pdfFinal act': '/oeil/en/procedure-file/pdf?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0056(COD)</td>\n",
       "      <td>Common rules for imports: suspension of certai...</td>\n",
       "      <td>6.20.02 Export/import control, trade defence, ...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'07/03/2025': [{'Date': '07/03/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0056(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>{'pdfFinal act': '/oeil/en/procedure-file/pdf?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0404(COD)</td>\n",
       "      <td>Simplifying and reducing the burden of the rul...</td>\n",
       "      <td>3.30.06 Information and communication technolo...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'16/12/2025': [{'Date': '16/12/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0404(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>https://oeil.europarl.europa.eu/oeil/en/proced...</td>\n",
       "      <td>2025/0726(COD)</td>\n",
       "      <td>Negative trade-related effects of global overc...</td>\n",
       "      <td>3.40.02 Iron and steel industry, metallurgical...</td>\n",
       "      <td>{'European Parliament': [{'Committee responsib...</td>\n",
       "      <td>{'07/10/2025': [{'Date': '07/10/2025', 'Event'...</td>\n",
       "      <td>{'Procedure reference': '2025/0726(COD)', 'Pro...</td>\n",
       "      <td>[{'Institution': 'European Commission', 'Docum...</td>\n",
       "      <td>{'Rapporteurs, Shadow Rapporteurs and Committe...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url       reference  \\\n",
       "0    https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0255(COD)   \n",
       "1    https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0405(COD)   \n",
       "2    https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0540(COD)   \n",
       "3    https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0550(COD)   \n",
       "4    https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0227(COD)   \n",
       "..                                                 ...             ...   \n",
       "114  https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0232(COD)   \n",
       "115  https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0074(COD)   \n",
       "116  https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0056(COD)   \n",
       "117  https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0404(COD)   \n",
       "118  https://oeil.europarl.europa.eu/oeil/en/proced...  2025/0726(COD)   \n",
       "\n",
       "                                                 title  \\\n",
       "0                          Justice programme 2028-2034   \n",
       "1    Placing on the market of genetically modified ...   \n",
       "2    Union support for asylum, migration and integr...   \n",
       "3                        'AgoraEU' programme 2028–2034   \n",
       "4                                        Global Europe   \n",
       "..                                                 ...   \n",
       "114  Protection of workers from the risks related t...   \n",
       "115  Extension of the timeframe for the establishme...   \n",
       "116  Common rules for imports: suspension of certai...   \n",
       "117  Simplifying and reducing the burden of the rul...   \n",
       "118  Negative trade-related effects of global overc...   \n",
       "\n",
       "                                              subjects  \\\n",
       "0    7.40.02 Judicial cooperation in civil and comm...   \n",
       "1    3.10.09.06 Agro-genetics, GMOs, 4.60.02 Consum...   \n",
       "2    7.10 Free movement and integration of third-co...   \n",
       "3    1.20 Citizen's rights, 4.10.03 Child protectio...   \n",
       "4    6.20 Common commercial policy in general, 8.70...   \n",
       "..                                                 ...   \n",
       "114  4.15.15 Health and safety at work, occupationa...   \n",
       "115  7.30.30 Action to combat crime, 7.40.04 Judici...   \n",
       "116  6.20.02 Export/import control, trade defence, ...   \n",
       "117  3.30.06 Information and communication technolo...   \n",
       "118  3.40.02 Iron and steel industry, metallurgical...   \n",
       "\n",
       "                                           key_players  \\\n",
       "0    {'European Parliament': [{'Joint committee res...   \n",
       "1    {'European Parliament': [{'Joint committee res...   \n",
       "2    {'European Parliament': [{'Committee responsib...   \n",
       "3    {'European Parliament': [{'Joint committee res...   \n",
       "4    {'European Parliament': [{'Joint committee res...   \n",
       "..                                                 ...   \n",
       "114  {'European Parliament': [{'Committee responsib...   \n",
       "115  {'European Parliament': [{'Committee responsib...   \n",
       "116  {'European Parliament': [{'Committee responsib...   \n",
       "117  {'European Parliament': [{'Committee responsib...   \n",
       "118  {'European Parliament': [{'Committee responsib...   \n",
       "\n",
       "                                            key_events  \\\n",
       "0    {'03/09/2025': [{'Date': '03/09/2025', 'Event'...   \n",
       "1    {'16/12/2025': [{'Date': '16/12/2025', 'Event'...   \n",
       "2    {'16/07/2025': [{'Date': '16/07/2025', 'Event'...   \n",
       "3    {'16/07/2025': [{'Date': '16/07/2025', 'Event'...   \n",
       "4    {'16/07/2025': [{'Date': '16/07/2025', 'Event'...   \n",
       "..                                                 ...   \n",
       "114  {'18/07/2025': [{'Date': '18/07/2025', 'Event'...   \n",
       "115  {'02/04/2025': [{'Date': '02/04/2025', 'Event'...   \n",
       "116  {'07/03/2025': [{'Date': '07/03/2025', 'Event'...   \n",
       "117  {'16/12/2025': [{'Date': '16/12/2025', 'Event'...   \n",
       "118  {'07/10/2025': [{'Date': '07/10/2025', 'Event'...   \n",
       "\n",
       "                                        technical_info  \\\n",
       "0    {'Procedure reference': '2025/0255(COD)', 'Pro...   \n",
       "1    {'Procedure reference': '2025/0405(COD)', 'Pro...   \n",
       "2    {'Procedure reference': '2025/0540(COD)', 'Pro...   \n",
       "3    {'Procedure reference': '2025/0550(COD)', 'Pro...   \n",
       "4    {'Procedure reference': '2025/0227(COD)', 'Pro...   \n",
       "..                                                 ...   \n",
       "114  {'Procedure reference': '2025/0232(COD)', 'Pro...   \n",
       "115  {'Procedure reference': '2025/0074(COD)', 'Pro...   \n",
       "116  {'Procedure reference': '2025/0056(COD)', 'Pro...   \n",
       "117  {'Procedure reference': '2025/0404(COD)', 'Pro...   \n",
       "118  {'Procedure reference': '2025/0726(COD)', 'Pro...   \n",
       "\n",
       "                                 documentation_gateway  \\\n",
       "0    [{'Institution': 'European Commission', 'Docum...   \n",
       "1    [{'Institution': 'European Commission', 'Docum...   \n",
       "2    [{'Institution': 'European Commission', 'Docum...   \n",
       "3    [{'Institution': 'European Commission', 'Docum...   \n",
       "4    [{'Institution': 'European Commission', 'Docum...   \n",
       "..                                                 ...   \n",
       "114  [{'Institution': 'European Commission', 'Docum...   \n",
       "115  [{'Institution': 'European Commission', 'Docum...   \n",
       "116  [{'Institution': 'European Commission', 'Docum...   \n",
       "117  [{'Institution': 'European Commission', 'Docum...   \n",
       "118  [{'Institution': 'European Commission', 'Docum...   \n",
       "\n",
       "                                          transparency  \\\n",
       "0                                                  N/A   \n",
       "1                                                  N/A   \n",
       "2    {'Other Members': [{'Name': [{'text': 'ASENS L...   \n",
       "3    {'Rapporteurs, Shadow Rapporteurs and Committe...   \n",
       "4                                                  N/A   \n",
       "..                                                 ...   \n",
       "114  {'Rapporteurs, Shadow Rapporteurs and Committe...   \n",
       "115                                                N/A   \n",
       "116                                                N/A   \n",
       "117                                                N/A   \n",
       "118  {'Rapporteurs, Shadow Rapporteurs and Committe...   \n",
       "\n",
       "                                             final_act  \n",
       "0                                                  N/A  \n",
       "1                                                  N/A  \n",
       "2                                                  N/A  \n",
       "3                                                  N/A  \n",
       "4                                                  N/A  \n",
       "..                                                 ...  \n",
       "114                                                N/A  \n",
       "115  {'pdfFinal act': '/oeil/en/procedure-file/pdf?...  \n",
       "116  {'pdfFinal act': '/oeil/en/procedure-file/pdf?...  \n",
       "117                                                N/A  \n",
       "118                                                N/A  \n",
       "\n",
       "[119 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the scraped data\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
